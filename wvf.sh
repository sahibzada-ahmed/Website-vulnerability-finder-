#!/bin/bash

# Tool Information
echo -e "\e[92m"
echo "=========================================="
echo "    OWASP Top 10 Vulnerability Scanner    "
echo "    Made by Cyber Vigilance PK & Faraz Ahmed"
echo "=========================================="
echo -e "\e[0m"

# Function to check and install missing dependencies
install_dependencies() {
    dependencies=("curl" "jq" "python3" "pip")
    for dep in "${dependencies[@]}"; do
        if ! command -v $dep &>/dev/null; then
            echo "$dep not found. Installing..."
            pkg install -y $dep
        fi
    done
    pip install requests beautifulsoup4
}

# Function to ensure the URL has a valid scheme
validate_url() {
    if [[ ! $1 =~ ^https?:// ]]; then
        echo "No scheme found in the URL, adding http://"
        echo "http://$1"
    else
        echo "$1"
    fi
}

# Function to Crawl and Gather URLs from a Website
crawl_website() {
    echo -e "\e[93m[+] Crawling $1 for URLs...\e[0m"
    python3 -c "
import requests
from bs4 import BeautifulSoup
import urllib.parse

url = \"$1\"
visited = set()
urls_to_scan = set([url])

def get_links(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        for a_tag in soup.find_all('a', href=True):
            href = a_tag['href']
            full_url = urllib.parse.urljoin(url, href)
            if full_url not in visited and url in full_url:
                visited.add(full_url)
                urls_to_scan.add(full_url)
    except Exception as e:
        print(f'[-] Failed to crawl {url}:', e)

while urls_to_scan:
    current_url = urls_to_scan.pop()
    visited.add(current_url)
    get_links(current_url)

print(f'[+] Found {len(visited)} URLs to scan.')
with open('urls.txt', 'w') as f:
    for url in visited:
        f.write(f'{url}\n')
"
}

# Function to Scan for SQL Injection
scan_sqli() {
    echo -e "\e[93m[+] Scanning for SQL Injection...\e[0m"
    python3 -c "
import requests

url = \"$1\"
payloads = ['\' OR \'1\'=\'1', '\' OR 1=1--', '\' OR 1=1#', '\" OR \"1\"=\"1', '\" OR 1=1--', '\" OR 1=1#']

vulnerable = False
for payload in payloads:
    try:
        r = requests.get(url, params={'id': payload})
        if 'syntax error' in r.text.lower() or 'mysql' in r.text.lower() or 'error' in r.text.lower():
            print('[!] Potential SQL Injection vulnerability found at', url, 'with payload:', payload)
            vulnerable = True
            break
    except requests.exceptions.RequestException as e:
        print(f'[-] Error during scanning {url}:', e)

if not vulnerable:
    print('[-] No SQL Injection vulnerability detected at', url)
"
}

# Function to Scan for Cross-Site Scripting (XSS)
scan_xss() {
    echo -e "\e[93m[+] Scanning for Cross-Site Scripting (XSS)...\e[0m"
    python3 -c "
import requests

url = \"$1\"
payloads = ['<script>alert(1)</script>', '\" onmouseover=\"alert(1)\"', '><script>alert(1)</script>']

vulnerable = False
for payload in payloads:
    try:
        r = requests.get(url, params={'q': payload})
        if payload in r.text:
            print('[!] Potential XSS vulnerability found at', url, 'with payload:', payload)
            vulnerable = True
            break
    except requests.exceptions.RequestException as e:
        print(f'[-] Error during scanning {url}:', e)

if not vulnerable:
    print('[-] No XSS vulnerability detected at', url)
"
}

# Function to Scan all URLs for SQL Injection and XSS
scan_all_urls() {
    while IFS= read -r url; do
        scan_sqli "$url"
        scan_xss "$url"
    done < urls.txt
}

# Function to Generate Report
generate_report() {
    echo -e "\e[93m[+] Generating detailed report...\e[0m"
    python3 -c "
import os

with open('urls.txt', 'r') as urls:
    with open('scan_report.txt', 'w') as report:
        report.write('Vulnerability Scan Report\n')
        report.write('=========================\n\n')
        for url in urls:
            report.write(f'Scanned URL: {url.strip()}\n')
            report.write('SQL Injection: \n')
            report.write('Cross-Site Scripting (XSS): \n\n')
        print(f'[+] Report saved as scan_report.txt')
"
}

# Main Script Execution
install_dependencies

echo -n "Enter the URL to scan (e.g., https://example.com): "
read url
url=$(validate_url "$url")

echo -n "Enable verbose mode? (y/n): "
read verbose

# Start crawling and scanning for vulnerabilities
echo -e "\e[93m[+] Starting scan on $url\e[0m"
crawl_website "$url"

if [[ "$verbose" == "y" ]]; then
    set -x
fi

scan_all_urls
generate_report

if [[ "$verbose" == "y" ]]; then
    set +x
fi

echo -e "\e[92m[+] Scanning complete. Review the results above and in scan_report.txt.\e[0m"
