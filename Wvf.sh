#!/bin/bash

# Tool Information
echo -e "\e[92m"
echo "=========================================="
echo "    OWASP Top 10 Vulnerability Scanner    "
echo "    Made by Cyber Vigilance PK & Faraz Ahmed"
echo "=========================================="
echo -e "\e[0m"

# Log file
log_file="scan.log"
> "$log_file"  # Empty the log file at the start

# Function to check and install missing dependencies
install_dependencies() {
    dependencies=("curl" "jq" "python3" "pip")
    for dep in "${dependencies[@]}"; do
        if ! command -v $dep &>/dev/null; then
            echo -e "\e[91m[!] $dep not found. Installing...\e[0m" | tee -a "$log_file"
            if [ "$(uname)" == "Linux" ]; then
                apt install -y $dep  # Use apt for Linux
            else
                echo -e "\e[91m[-] Unsupported OS\e[0m" | tee -a "$log_file"
                exit 1
            fi
        fi
    done
    pip install --upgrade requests beautifulsoup4 | tee -a "$log_file"
}

# Function to validate and check if URL is reachable
validate_url() {
    if [[ ! $1 =~ ^https?:// ]]; then
        echo -e "\e[93m[!] No scheme found in the URL, adding http://\e[0m" | tee -a "$log_file"
        url="http://$1"
    else
        url="$1"
    fi

    # Check if URL is reachable
    if curl --output /dev/null --silent --head --fail "$url"; then
        echo -e "\e[92m[+] $url is valid and reachable.\e[0m" | tee -a "$log_file"
    else
        echo -e "\e[91m[-] Invalid or unreachable URL.\e[0m" | tee -a "$log_file"
        exit 1
    fi
}

# Verbose mode function
verbose=false
enable_verbose() {
    if [[ "$verbose" == true ]]; then
        set -x
    fi
}

disable_verbose() {
    if [[ "$verbose" == true ]]; then
        set +x
    fi
}

# Crawling website for URLs
crawl_website() {
    echo -e "\e[93m[+] Crawling $1 for URLs...\e[0m" | tee -a "$log_file"
    python3 -c "
import requests
from bs4 import BeautifulSoup
import urllib.parse

url = \"$1\"
visited = set()
urls_to_scan = set([url])

def get_links(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        for a_tag in soup.find_all('a', href=True):
            href = a_tag['href']
            full_url = urllib.parse.urljoin(url, href)
            if full_url not in visited and url in full_url:
                visited.add(full_url)
                urls_to_scan.add(full_url)
    except Exception as e:
        print(f'[-] Failed to crawl {url}:', e)

while urls_to_scan:
    current_url = urls_to_scan.pop()
    visited.add(current_url)
    get_links(current_url)

print(f'[+] Found {len(visited)} URLs to scan.')
with open('urls.txt', 'w') as f:
    for url in visited:
        f.write(f'{url}\n')
" | tee -a "$log_file"
}

# Scan for SQL Injection with more payloads
scan_sqli() {
    echo -e "\e[93m[+] Scanning for SQL Injection...\e[0m" | tee -a "$log_file"
    python3 -c "
import requests

url = \"$1\"
payloads = ['\' OR \'1\'=\'1', '\' OR 1=1--', '\' OR 1=1#', '\" OR \"1\"=\"1', 'admin\'--', '\' UNION SELECT null, null --']

vulnerable = False
for payload in payloads:
    try:
        r = requests.get(url, params={'id': payload})
        if 'syntax error' in r.text.lower() or 'mysql' in r.text.lower() or 'ORA-' in r.text:
            print(f'[!] Potential SQL Injection vulnerability found at {url} with payload: {payload}')
            vulnerable = True
            break
    except requests.exceptions.RequestException as e:
        print(f'[-] Error during scanning {url}:', e)

if not vulnerable:
    print(f'[-] No SQL Injection vulnerability detected at {url}')
" | tee -a "$log_file"
}

# Scan for Cross-Site Scripting (XSS)
scan_xss() {
    echo -e "\e[93m[+] Scanning for Cross-Site Scripting (XSS)...\e[0m" | tee -a "$log_file"
    python3 -c "
import requests

url = \"$1\"
payloads = ['<script>alert(1)</script>', '\" onmouseover=\"alert(1)\"', '<img src=x onerror=alert(1)>']

vulnerable = False
for payload in payloads:
    try:
        r = requests.get(url, params={'q': payload})
        if payload in r.text:
            print(f'[!] Potential XSS vulnerability found at {url} with payload: {payload}')
            vulnerable = True
            break
    except requests.exceptions.RequestException as e:
        print(f'[-] Error during scanning {url}:', e)

if not vulnerable:
    print(f'[-] No XSS vulnerability detected at {url}')
" | tee -a "$log_file"
}

# Scan for Open Redirect
scan_open_redirect() {
    echo -e "\e[93m[+] Scanning for Open Redirect...\e[0m" | tee -a "$log_file"
    python3 -c "
import requests

url = \"$1\"
payloads = ['https://evil.com', 'https://malicious.com']

vulnerable = False
for payload in payloads:
    try:
        r = requests.get(url, params={'next': payload})
        if r.url == payload:
            print(f'[!] Potential Open Redirect vulnerability found at {url} with redirect to: {payload}')
            vulnerable = True
            break
    except requests.exceptions.RequestException as e:
        print(f'[-] Error during scanning {url}:', e)

if not vulnerable:
    print(f'[-] No Open Redirect vulnerability detected at {url}')
" | tee -a "$log_file"
}

# Scan for Directory Traversal
scan_dir_traversal() {
    echo -e "\e[93m[+] Scanning for Directory Traversal...\e[0m" | tee -a "$log_file"
    python3 -c "
import requests

url = \"$1\"
payloads = ['../etc/passwd', '../../etc/passwd', '/etc/passwd']

vulnerable = False
for payload in payloads:
    try:
        r = requests.get(url, params={'file': payload})
        if 'root:x' in r.text or 'root' in r.text:
            print(f'[!] Potential Directory Traversal vulnerability found at {url} with payload: {payload}')
            vulnerable = True
            break
    except requests.exceptions.RequestException as e:
        print(f'[-] Error during scanning {url}:', e)

if not vulnerable:
    print(f'[-] No Directory Traversal vulnerability detected at {url}')
" | tee -a "$log_file"
}

# Function to scan all URLs
scan_all_urls() {
    while IFS= read -r url; do
        scan_sqli "$url"
        scan_xss "$url"
        scan_open_redirect "$url"
        scan_dir_traversal "$url"
    done < urls.txt
}

# Function to generate detailed JSON report
generate_report() {
    echo -e "\e[93m[+] Generating detailed report...\e[0m" | tee -a "$log_file"
    python3 -c "
import json

with open('urls.txt', 'r') as urls, open('scan_report.json', 'w') as report:
    results = []
    for url in urls:
        result = {
            'url': url.strip(),
            'SQL Injection': 'Not Vulnerable',
            'Cross-Site Scripting (XSS)': 'Not Vulnerable',
            'Open Redirect': 'Not Vulnerable',
            'Directory Traversal': 'Not Vulnerable'
        }
        results.append(result)
    json.dump(results, report, indent=4)
print('[+] Detailed report saved as scan_report.json')
" | tee -a "$log_file"
}

# Main Script Execution
install_dependencies

echo -n "Enter the URL to scan (e.g., https://example.com): "
read url
url=$(validate_url "$url")

echo -n "Enable verbose mode? (y/n): "
read verbose_mode
if [[ "$verbose_mode" == "y" ]]; then
    verbose=true
fi

# Start crawling and scanning for vulnerabilities
echo -e "\e[93m[+] Starting crawl and scan...\e[0m" | tee -a "$log_file"
crawl_website "$url"
scan_all_urls

# Generate report
generate_report
